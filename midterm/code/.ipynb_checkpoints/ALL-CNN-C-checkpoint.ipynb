{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "cifar10_train = torchvision.datasets.CIFAR10(root='../data/CIFAR10', train=True,\n",
    "                                           download=True, transform=transform)\n",
    "loader_train = torch.utils.data.DataLoader(cifar10_train, batch_size=64,\n",
    "                                      sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "cifar10_val = torchvision.datasets.CIFAR10(root='../data/CIFAR10', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "loader_val = torch.utils.data.DataLoader(cifar10_train, batch_size=64,\n",
    "                                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "cifar10_test = torchvision.datasets.CIFAR10(root='../data/CIFAR10', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "loader_test = torch.utils.data.DataLoader(cifar10_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = iter(loader_train).next()\n",
    "print(\"train_X:\", train_images.size(), \"train_y:\", train_labels.size())\n",
    "val_images, val_labels = iter(loader_val).next()\n",
    "print(\"val_X:\", val_images.size(), \"val_y:\", val_labels.size())\n",
    "test_images, test_labels = iter(loader_test).next()\n",
    "print(\"test_X:\", test_images.size(), \"test_y:\", test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, \n",
    "                 channel_3, channel_4, num_classes):\n",
    "        \"\"\"\n",
    "        Default initialization:\n",
    "        model = Model(in_channel=3, channel_1=96, channel_2=192, \n",
    "                 channel_3=192, channel_4=192, num_classes=10)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channel, channel_1, 3, padding=1)           #(3, 96, 3)\n",
    "        self.conv1_2 = nn.Conv2d(channel_1, channel_1, 3, padding=1)            #(96, 96, 3)\n",
    "        self.conv1_3 = nn.Conv2d(channel_1, channel_1, 3, padding=1, stride=2)  #(96, 96, 3)\n",
    "        self.conv2_1 = nn.Conv2d(channel_1, channel_2, 3, padding=1)            #(96, 192, 3)\n",
    "        self.conv2_2 = nn.Conv2d(channel_2, channel_2, 3, padding=1)            #(192, 192, 3)\n",
    "        self.conv2_3 = nn.Conv2d(channel_2, channel_2, 3, padding=1, stride=2)  #(192, 192, 3)\n",
    "        self.conv3 = nn.Conv2d(channel_2, channel_3, 3)                         #(192, 192, 3)\n",
    "        self.conv4 = nn.Conv2d(channel_3, channel_4, 1)                         #(192, 192, 1)\n",
    "        self.conv5 = nn.Conv2d(channel_4, num_classes, 1)                       #(192, 10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x.shape: (64, 3, 32, 32)\n",
    "        \"\"\"\n",
    "        N = x.shape[0]\n",
    "        x_drop = F.dropout(x, .2)\n",
    "        conv1_1_out = F.relu(self.conv1_1(x_drop))            # (64, 96, 32, 32)\n",
    "        conv1_2_out = F.relu(self.conv1_2(conv1_1_out))  # (64, 96, 32, 32)\n",
    "        layer1_out = F.relu(self.conv1_3(conv1_2_out))  # (64, 96, 32, 32)\n",
    "        layer1_out_drop = F.dropout(layer1_out, .5)\n",
    "        conv2_1_out = F.relu(self.conv2_1(layer1_out_drop))   # (64, 192, 16, 16)\n",
    "        conv2_2_out = F.relu(self.conv2_2(conv2_1_out))   # (64, 192, 16, 16)        \n",
    "        layer2_out = F.relu(self.conv2_3(conv2_2_out))   # (64, 192, 16, 16)\n",
    "        layer2_out_drop = F.dropout(layer2_out, .5)  \n",
    "        layer3_out = F.relu(self.conv3(layer2_out_drop))             # (64, 192, 6, 6)\n",
    "        layer4_out = F.relu(self.conv4(layer3_out))             # (64, 192, 6, 6)\n",
    "        layer5_out = F.relu(self.conv5(layer4_out))             # (64, 10, 6, 6)\n",
    "#         print(x.size(), conv1_1_out.size(), conv1_2_out.size(), layer1_out.size(), layer4_out.size(), layer5_out.size())\n",
    "        out = layer5_out.view(N, 10, -1).mean(dim=2)\n",
    "        return out\n",
    "        \n",
    "def test_Model():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
    "    model = Model(in_channel=3, channel_1=96, channel_2=192, \n",
    "                 channel_3=192, channel_4=192, num_classes=10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())\n",
    "test_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set') \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x_lst, y_lst, path, name, xlabel, ylabel):\n",
    "    plt.plot(x_lst, y_lst)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    plt.savefig(path + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 100\n",
    "    \n",
    "def train(model, optimizer, scheduler, weight_decay=0.001, epochs=1, best_acc=0.0):\n",
    "    loss_his = []\n",
    "    epoch_lst = []\n",
    "    acc_his = []\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    model = nn.DataParallel(model,device_ids=[0,1])  \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        scheduler.step()\n",
    "        for step, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, step, loss.item()))\n",
    "                acc = check_accuracy(loader_val, model)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                fo = open(\"model_all_cnn_c.log\", \"a\")\n",
    "                fo.write(\"Epoch: {}\\t Step: {}\\t loss: {:.4f}\\t accuracy: {:.2f}\\n\"\\\n",
    "                         .format(e, step, learning_rate, loss.item(), acc))\n",
    "                fo.close()\n",
    "                print()\n",
    "        epoch_lst.append(e)\n",
    "        loss_his.append(loss.item())\n",
    "        acc_his.append(acc)\n",
    "    \n",
    "    plot(epoch_lst, loss_his, path=\"../results figure/\", name=\"Model ALL CNN C_Loss accross Epoch\", \n",
    "        xlabel=\"epoch\", ylabel=\"loss\")\n",
    "    plot(epoch_lst, acc_his, path=\"../results figure/\", name=\"Model ALL CNN C_Accuracy accross Epoch\",\n",
    "        xlabel=\"epoch\", ylabel=\"accuracy\")\n",
    "    \n",
    "    print(\"Best accuracy:\", best_acc)\n",
    "    fo = open(\"model_all_cnn_c.log\", \"a\")\n",
    "    fo.write(\"Best accuracy: {}\".format(best_acc))\n",
    "    fo.close()\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lst = [0.25]\n",
    "\n",
    "fo = open(\"model_all_cnn_c.log\", \"w\")\n",
    "fo.write(\"Model All CNN C Trainning log\\n\")\n",
    "fo.close()\n",
    "\n",
    "for learning_rate in lr_lst:\n",
    "    fo = open(\"model_all_cnn_c.log\", \"a\")\n",
    "    fo.write(\"\\nOriginal Learning rate: {}\\n\".format(learning_rate))\n",
    "    fo.close()\n",
    "    print(\"Learning_rate:\", learning_rate)\n",
    "    model = Model(in_channel=3, channel_1=96, channel_2=192, \n",
    "             channel_3=192, channel_4=192, num_classes=10) \n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, weight_decay=0.001)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                               milestones=[200, 250, 300], gamma=0.1)\n",
    "    best_model = train(model, optimizer, scheduler, epochs=350, best_acc=0.0)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../best_model/\"\n",
    "model_name = \"best_model_all_cnn_c.pt\"\n",
    "if not os.path.exists(PATH):\n",
    "    os.mkdir(PATH)\n",
    "torch.save(best_model.state_dict(), PATH + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
