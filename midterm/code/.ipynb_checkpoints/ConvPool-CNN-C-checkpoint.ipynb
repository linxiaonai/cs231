{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "cifar10_train = torchvision.datasets.CIFAR10(root='../data/CIFAR10', train=True,\n",
    "                                           download=True, transform=transform)\n",
    "loader_train = torch.utils.data.DataLoader(cifar10_train, batch_size=64,\n",
    "                                      sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "cifar10_val = torchvision.datasets.CIFAR10(root='../data/CIFAR10', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "loader_val = torch.utils.data.DataLoader(cifar10_train, batch_size=64,\n",
    "                                    sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "cifar10_test = torchvision.datasets.CIFAR10(root='../data/CIFAR10', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "loader_test = torch.utils.data.DataLoader(cifar10_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X: torch.Size([64, 3, 32, 32]) train_y: torch.Size([64])\n",
      "val_X: torch.Size([64, 3, 32, 32]) val_y: torch.Size([64])\n",
      "test_X: torch.Size([64, 3, 32, 32]) test_y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = iter(loader_train).next()\n",
    "print(\"train_X:\", train_images.size(), \"train_y:\", train_labels.size())\n",
    "val_images, val_labels = iter(loader_val).next()\n",
    "print(\"val_X:\", val_images.size(), \"val_y:\", val_labels.size())\n",
    "test_images, test_labels = iter(loader_test).next()\n",
    "print(\"test_X:\", test_images.size(), \"test_y:\", test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('using device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, \n",
    "                 channel_3, channel_4, num_classes):\n",
    "        \"\"\"\n",
    "        Default initialization:\n",
    "        model = Model(in_channel=3, channel_1=96, channel_2=192, \n",
    "                 channel_3=192, channel_4=192, num_classes=10)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channel, channel_1, 3, padding=1)  #(3, 96, 3)\n",
    "        self.conv1_2 = nn.Conv2d(channel_1, channel_1, 3, padding=1)   #(96, 96, 3)\n",
    "        self.conv1_3 = nn.Conv2d(channel_1, channel_1, 3, padding=1)  #(96, 96, 3)\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(channel_1, channel_2, 3, padding=1)   #(96, 192, 3)\n",
    "        self.conv2_2 = nn.Conv2d(channel_2, channel_2, 3, padding=1)   #(192, 192, 3)\n",
    "        self.conv2_3 = nn.Conv2d(channel_2, channel_2, 3, padding=1)  #(192, 192, 3)\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(channel_2, channel_3, 3)   #(192, 192, 3)\n",
    "        self.conv4 = nn.Conv2d(channel_3, channel_4, 1)   #(192, 192, 1)\n",
    "        self.conv5 = nn.Conv2d(channel_4, num_classes, 1) #(192, 10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x.shape: (64, 3, 32, 32)\n",
    "        \"\"\"\n",
    "        N = x.shape[0]\n",
    "        x_drop = F.dropout(x, .2)\n",
    "        conv1_1_out = F.relu(self.conv1_1(x_drop))            # (64, 96, 32, 32)\n",
    "        conv1_2_out = F.relu(self.conv1_2(conv1_1_out))  # (64, 96, 32, 32)\n",
    "        conv1_3_out = F.relu(self.conv1_3(conv1_2_out))  # (64, 96, 32, 32)\n",
    "        layer1_out = self.pool1(conv1_3_out)                        # (64, 96, 16, 16)\n",
    "        layer1_out_drop = F.dropout(layer1_out, .5)\n",
    "        conv2_1_out = F.relu(self.conv2_1(layer1_out_drop))   # (64, 192, 16, 16)\n",
    "        conv2_2_out = F.relu(self.conv2_2(conv2_1_out))   # (64, 192, 16, 16)        \n",
    "        conv2_3_out = F.relu(self.conv2_3(conv2_2_out))   # (64, 192, 16, 16)        \n",
    "        layer2_out = self.pool2(conv2_3_out)                      # (64, 192, 8, 8)\n",
    "        layer2_out_drop = F.dropout(layer2_out, .5)\n",
    "        layer3_out = F.relu(self.conv3(layer2_out_drop))             # (64, 192, 6, 6)\n",
    "        layer4_out = F.relu(self.conv4(layer3_out))             # (64, 192, 6, 6)\n",
    "        layer5_out = F.relu(self.conv5(layer4_out))             # (64, 10, 6, 6)\n",
    "#         print(x.size(), conv1_1_out.size(), conv1_2_out.size(), layer1_out.size(),layer5_out.size())\n",
    "        out = layer5_out.view(N, 10, -1).mean(dim=2)\n",
    "        return out\n",
    "        \n",
    "def test_Model():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
    "    model = Model(in_channel=3, channel_1=96, channel_2=192, \n",
    "                 channel_3=192, channel_4=192, num_classes=10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())\n",
    "test_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set') \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x_lst, y_lst, path, name, xlabel, ylabel):\n",
    "    plt.plot(x_lst, y_lst)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    plt.savefig(path + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 100\n",
    "    \n",
    "def train(model, optimizer, scheduler, weight_decay=0.001, epochs=1, best_acc=0.0):\n",
    "    loss_his = []\n",
    "    epoch_lst = []\n",
    "    acc_his = []\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    model = nn.DataParallel(model,device_ids=[0,1])  \n",
    "        \n",
    "    for e in range(epochs):\n",
    "        scheduler.step()\n",
    "        for step, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, step, loss.item()))\n",
    "                acc = check_accuracy(loader_val, model)\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                fo = open(\"model_convpool_cnn_c.log\", \"a\")\n",
    "                fo.write(\"Epoch: {}\\t Step: {}\\t loss: {:.4f}\\t accuracy: {:.2f}\\n\"\\\n",
    "                         .format(e, step, loss.item(), acc))\n",
    "                fo.close()\n",
    "                print()\n",
    "        epoch_lst.append(e)\n",
    "        loss_his.append(loss.item())\n",
    "        acc_his.append(acc)\n",
    "    \n",
    "    plot(epoch_lst, loss_his, path=\"../results figure/\", name=\"Model ConvPool CNN C_Loss accross Epoch\", \n",
    "        xlabel=\"epoch\", ylabel=\"loss\")\n",
    "    plot(epoch_lst, acc_his, path=\"../results figure/\", name=\"Model ConvPool CNN C_Accuracy accross Epoch\",\n",
    "        xlabel=\"epoch\", ylabel=\"accuracy\")\n",
    "                \n",
    "    print(\"Best accuracy:\", best_acc)\n",
    "    fo = open(\"model_convpool_cnn_c.log\", \"a\")\n",
    "    fo.write(\"Best accuracy: {}\".format(best_acc))\n",
    "    fo.close()\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rate: 0.01\n",
      "Epoch 0, Iteration 0, loss = 2.2978\n",
      "Checking accuracy on validation set\n",
      "Got 78 / 1000 correct (7.80)\n",
      "\n",
      "Epoch 0, Iteration 100, loss = 2.2992\n",
      "Checking accuracy on validation set\n",
      "Got 119 / 1000 correct (11.90)\n",
      "\n",
      "Epoch 0, Iteration 200, loss = 2.3036\n",
      "Checking accuracy on validation set\n",
      "Got 79 / 1000 correct (7.90)\n",
      "\n",
      "Epoch 0, Iteration 300, loss = 2.3028\n",
      "Checking accuracy on validation set\n",
      "Got 78 / 1000 correct (7.80)\n",
      "\n",
      "Epoch 0, Iteration 400, loss = 2.3009\n",
      "Checking accuracy on validation set\n",
      "Got 90 / 1000 correct (9.00)\n",
      "\n",
      "Epoch 0, Iteration 500, loss = 2.3010\n",
      "Checking accuracy on validation set\n",
      "Got 114 / 1000 correct (11.40)\n",
      "\n",
      "Epoch 0, Iteration 600, loss = 2.2935\n",
      "Checking accuracy on validation set\n",
      "Got 141 / 1000 correct (14.10)\n",
      "\n",
      "Epoch 0, Iteration 700, loss = 2.2944\n",
      "Checking accuracy on validation set\n",
      "Got 161 / 1000 correct (16.10)\n",
      "\n",
      "Epoch 1, Iteration 0, loss = 2.2311\n",
      "Checking accuracy on validation set\n",
      "Got 170 / 1000 correct (17.00)\n",
      "\n",
      "Epoch 1, Iteration 100, loss = 2.0741\n",
      "Checking accuracy on validation set\n",
      "Got 177 / 1000 correct (17.70)\n",
      "\n",
      "Epoch 1, Iteration 200, loss = 2.1388\n",
      "Checking accuracy on validation set\n",
      "Got 180 / 1000 correct (18.00)\n",
      "\n",
      "Epoch 1, Iteration 300, loss = 1.9125\n",
      "Checking accuracy on validation set\n",
      "Got 282 / 1000 correct (28.20)\n",
      "\n",
      "Epoch 1, Iteration 400, loss = 1.9199\n",
      "Checking accuracy on validation set\n",
      "Got 270 / 1000 correct (27.00)\n",
      "\n",
      "Epoch 1, Iteration 500, loss = 1.9135\n",
      "Checking accuracy on validation set\n",
      "Got 265 / 1000 correct (26.50)\n",
      "\n",
      "Epoch 1, Iteration 600, loss = 1.7326\n",
      "Checking accuracy on validation set\n",
      "Got 302 / 1000 correct (30.20)\n",
      "\n",
      "Epoch 1, Iteration 700, loss = 1.8096\n",
      "Checking accuracy on validation set\n",
      "Got 289 / 1000 correct (28.90)\n",
      "\n",
      "Epoch 2, Iteration 0, loss = 1.8604\n",
      "Checking accuracy on validation set\n",
      "Got 320 / 1000 correct (32.00)\n",
      "\n",
      "Epoch 2, Iteration 100, loss = 1.6705\n",
      "Checking accuracy on validation set\n",
      "Got 314 / 1000 correct (31.40)\n",
      "\n",
      "Epoch 2, Iteration 200, loss = 1.9290\n",
      "Checking accuracy on validation set\n",
      "Got 287 / 1000 correct (28.70)\n",
      "\n",
      "Epoch 2, Iteration 300, loss = 1.6521\n",
      "Checking accuracy on validation set\n",
      "Got 373 / 1000 correct (37.30)\n",
      "\n",
      "Epoch 2, Iteration 400, loss = 1.8864\n",
      "Checking accuracy on validation set\n",
      "Got 344 / 1000 correct (34.40)\n",
      "\n",
      "Epoch 2, Iteration 500, loss = 1.5868\n",
      "Checking accuracy on validation set\n",
      "Got 327 / 1000 correct (32.70)\n",
      "\n",
      "Epoch 2, Iteration 600, loss = 1.6476\n",
      "Checking accuracy on validation set\n",
      "Got 409 / 1000 correct (40.90)\n",
      "\n",
      "Epoch 2, Iteration 700, loss = 1.6294\n",
      "Checking accuracy on validation set\n",
      "Got 350 / 1000 correct (35.00)\n",
      "\n",
      "Epoch 3, Iteration 0, loss = 1.6570\n",
      "Checking accuracy on validation set\n",
      "Got 426 / 1000 correct (42.60)\n",
      "\n",
      "Epoch 3, Iteration 100, loss = 1.6374\n",
      "Checking accuracy on validation set\n",
      "Got 420 / 1000 correct (42.00)\n",
      "\n",
      "Epoch 3, Iteration 200, loss = 1.5492\n",
      "Checking accuracy on validation set\n",
      "Got 383 / 1000 correct (38.30)\n",
      "\n",
      "Epoch 3, Iteration 300, loss = 1.2712\n",
      "Checking accuracy on validation set\n",
      "Got 417 / 1000 correct (41.70)\n",
      "\n",
      "Epoch 3, Iteration 400, loss = 1.4846\n",
      "Checking accuracy on validation set\n",
      "Got 454 / 1000 correct (45.40)\n",
      "\n",
      "Epoch 3, Iteration 500, loss = 1.3799\n",
      "Checking accuracy on validation set\n",
      "Got 449 / 1000 correct (44.90)\n",
      "\n",
      "Epoch 3, Iteration 600, loss = 1.3374\n",
      "Checking accuracy on validation set\n",
      "Got 448 / 1000 correct (44.80)\n",
      "\n",
      "Epoch 3, Iteration 700, loss = 1.5224\n",
      "Checking accuracy on validation set\n",
      "Got 481 / 1000 correct (48.10)\n",
      "\n",
      "Epoch 4, Iteration 0, loss = 1.2420\n",
      "Checking accuracy on validation set\n",
      "Got 481 / 1000 correct (48.10)\n",
      "\n",
      "Epoch 4, Iteration 100, loss = 1.3572\n",
      "Checking accuracy on validation set\n",
      "Got 489 / 1000 correct (48.90)\n",
      "\n",
      "Epoch 4, Iteration 200, loss = 1.2411\n",
      "Checking accuracy on validation set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "\n",
      "Epoch 4, Iteration 300, loss = 1.1731\n",
      "Checking accuracy on validation set\n",
      "Got 484 / 1000 correct (48.40)\n",
      "\n",
      "Epoch 4, Iteration 400, loss = 1.5042\n",
      "Checking accuracy on validation set\n",
      "Got 491 / 1000 correct (49.10)\n",
      "\n",
      "Epoch 4, Iteration 500, loss = 1.4310\n",
      "Checking accuracy on validation set\n",
      "Got 549 / 1000 correct (54.90)\n",
      "\n",
      "Epoch 4, Iteration 600, loss = 1.1993\n",
      "Checking accuracy on validation set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "\n",
      "Epoch 4, Iteration 700, loss = 1.1602\n",
      "Checking accuracy on validation set\n",
      "Got 530 / 1000 correct (53.00)\n",
      "\n",
      "Epoch 5, Iteration 0, loss = 1.4624\n",
      "Checking accuracy on validation set\n",
      "Got 577 / 1000 correct (57.70)\n",
      "\n",
      "Epoch 5, Iteration 100, loss = 1.0504\n",
      "Checking accuracy on validation set\n",
      "Got 557 / 1000 correct (55.70)\n",
      "\n",
      "Epoch 5, Iteration 200, loss = 1.3715\n",
      "Checking accuracy on validation set\n",
      "Got 588 / 1000 correct (58.80)\n",
      "\n",
      "Epoch 5, Iteration 300, loss = 1.3865\n",
      "Checking accuracy on validation set\n",
      "Got 582 / 1000 correct (58.20)\n",
      "\n",
      "Epoch 5, Iteration 400, loss = 0.9955\n",
      "Checking accuracy on validation set\n",
      "Got 605 / 1000 correct (60.50)\n",
      "\n",
      "Epoch 5, Iteration 500, loss = 1.1784\n",
      "Checking accuracy on validation set\n",
      "Got 569 / 1000 correct (56.90)\n",
      "\n",
      "Epoch 5, Iteration 600, loss = 1.2701\n",
      "Checking accuracy on validation set\n",
      "Got 601 / 1000 correct (60.10)\n",
      "\n",
      "Epoch 5, Iteration 700, loss = 1.3428\n",
      "Checking accuracy on validation set\n",
      "Got 562 / 1000 correct (56.20)\n",
      "\n",
      "Epoch 6, Iteration 0, loss = 1.0386\n",
      "Checking accuracy on validation set\n",
      "Got 615 / 1000 correct (61.50)\n",
      "\n",
      "Epoch 6, Iteration 100, loss = 1.1214\n",
      "Checking accuracy on validation set\n",
      "Got 557 / 1000 correct (55.70)\n",
      "\n",
      "Epoch 6, Iteration 200, loss = 1.1550\n",
      "Checking accuracy on validation set\n",
      "Got 623 / 1000 correct (62.30)\n",
      "\n",
      "Epoch 6, Iteration 300, loss = 1.3027\n",
      "Checking accuracy on validation set\n",
      "Got 644 / 1000 correct (64.40)\n",
      "\n",
      "Epoch 6, Iteration 400, loss = 0.9534\n",
      "Checking accuracy on validation set\n",
      "Got 619 / 1000 correct (61.90)\n",
      "\n",
      "Epoch 6, Iteration 500, loss = 1.2747\n",
      "Checking accuracy on validation set\n",
      "Got 635 / 1000 correct (63.50)\n",
      "\n",
      "Epoch 6, Iteration 600, loss = 0.6885\n",
      "Checking accuracy on validation set\n",
      "Got 642 / 1000 correct (64.20)\n",
      "\n",
      "Epoch 6, Iteration 700, loss = 1.0306\n",
      "Checking accuracy on validation set\n",
      "Got 595 / 1000 correct (59.50)\n",
      "\n",
      "Epoch 7, Iteration 0, loss = 1.0080\n",
      "Checking accuracy on validation set\n",
      "Got 611 / 1000 correct (61.10)\n",
      "\n",
      "Epoch 7, Iteration 100, loss = 1.0355\n",
      "Checking accuracy on validation set\n",
      "Got 603 / 1000 correct (60.30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_lst = [0.01]\n",
    "\n",
    "fo = open(\"model_convpool_cnn_c.log\", \"w\")\n",
    "fo.write(\"Model ConvPool CNN C Trainning log\\n\")\n",
    "fo.close()\n",
    "\n",
    "for learning_rate in lr_lst:\n",
    "    fo = open(\"model_convpool_cnn_c.log\", \"a\")\n",
    "    fo.write(\"\\nOriginal Learning rate: {}\\n\".format(learning_rate))\n",
    "    fo.close()\n",
    "    print(\"Learning_rate:\", learning_rate)\n",
    "    model = Model(in_channel=3, channel_1=96, channel_2=192, \n",
    "             channel_3=192, channel_4=192, num_classes=10) \n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, weight_decay=0.001)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                               milestones=[200, 250, 300], gamma=0.1)\n",
    "    best_model = train(model, optimizer, scheduler, epochs=350, best_acc=0.0)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../best_model/\"\n",
    "model_name = \"best_model_convpool_cnn_c.pt\"\n",
    "if not os.path.exists(PATH):\n",
    "    os.mkdir(PATH)\n",
    "torch.save(best_model.state_dict(), PATH + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
